{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ab3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle \n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import statistics\n",
    "import urllib\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "image_data_complete = None\n",
    "x_train = None\n",
    "y_train = None\n",
    "x_val = None\n",
    "y_val = None \n",
    "label_1 = None\n",
    "label_0 = None\n",
    "train = None\n",
    "val = None\n",
    "\n",
    "def json_to_dict_project():\n",
    "    json_file = \"anonymized_project.json\"\n",
    "    dict_data = None\n",
    "    with open(json_file) as jsonfile:\n",
    "        dict_data = json.load(jsonfile)\n",
    "    return dict_data\n",
    "def json_to_dict_reference():\n",
    "    json_file = \"references.json\"\n",
    "    dict_data = None\n",
    "    with open(json_file) as jsonfile:\n",
    "        dict_data = json.load(jsonfile)\n",
    "    return dict_data\n",
    "\n",
    "\n",
    "def answer_detector(reference_data, user_data):\n",
    "    answer = \"no\"\n",
    "    img_id = user_data[\"task_input\"][\"image_url\"][-12:-4]\n",
    "    if img_id in reference_data.keys():\n",
    "        truthy_value = reference_data[img_id]\n",
    "        if truthy_value[\"is_bicycle\"] == \"True\":\n",
    "            answer = \"yes\"\n",
    "        if user_data[\"task_output\"][\"answer\"] == answer:\n",
    "            return 1\n",
    "    return 0\n",
    "            \n",
    "def image_to_array(url):\n",
    "    img_size = 224\n",
    "    image = io.imread(url)\n",
    "    img_arr = image[...,::-1]\n",
    "    resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "    return resized_arr\n",
    "\n",
    "def data_to_array():\n",
    "    data = []\n",
    "    project_data = json_to_dict_project()\n",
    "    reference_data = json_to_dict_reference()\n",
    "    root_data = project_data[\"results\"][\"root_node\"][\"results\"]\n",
    "    for items in root_data:\n",
    "        for last_child in root_data[items][\"results\"]:\n",
    "            img_url = last_child[\"task_input\"][\"image_url\"]\n",
    "            if img_url not in done:\n",
    "                resized_array = image_to_array(img_url)\n",
    "                label = answer_detector(reference_data, last_child)\n",
    "                data.append([resized_array, label])\n",
    "    pickle.dump( data, open( \"data_save.pkl\", \"wb\" ) )\n",
    "    \n",
    "def load_saved_data():\n",
    "    global image_data_complete\n",
    "    ##Data saved in pickle file in case model has to be rerun, conversion takes time\n",
    "    #image_data_complete = pickle.load( open( \"data_save.pkl\", \"rb\" ) )\n",
    "    image_data_complete = pickle.load( open( \"data_save.pkl\", \"rb\" ) )\n",
    "\n",
    "def labels_generate():\n",
    "    global image_data_complete\n",
    "    global label_1\n",
    "    global label_0\n",
    "    label_1 = []\n",
    "    label_0 = []\n",
    "    for image in image_data_complete:\n",
    "        if image[1]== 1:\n",
    "            label_1.append(image)\n",
    "        else:\n",
    "            label_0.append(image)\n",
    "\n",
    "def generate_train_val():\n",
    "    global train\n",
    "    global val\n",
    "    train = label_1[:round(len(label_1)/2)] + label_0[:round(len(label_0)/2)]\n",
    "    val = train = label_1[round(len(label_1)/2):] + label_0[round(len(label_0)/2):]            \n",
    "\n",
    "def data_normalize():\n",
    "    global x_train\n",
    "    global y_train \n",
    "    global x_val\n",
    "    global y_val\n",
    "    global train\n",
    "    global val\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    img_size = 224\n",
    "    for feature, label in train:\n",
    "        x_train.append(feature)\n",
    "        y_train.append(label)\n",
    "\n",
    "    for feature, label in val:\n",
    "        x_val.append(feature)\n",
    "        y_val.append(label)\n",
    "\n",
    "    # Normalize the data\n",
    "    x_train = np.array(x_train) / 255\n",
    "    x_val = np.array(x_val) / 255\n",
    "\n",
    "    x_train.reshape(-1, img_size, img_size, 1)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    x_val.reshape(-1, img_size, img_size, 1)\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "def main_model():\n",
    "    global x_train\n",
    "    global y_train \n",
    "    global x_val\n",
    "    global y_val\n",
    "    global train\n",
    "    global val\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False, \n",
    "        rotation_range = 30, \n",
    "        zoom_range = 0.2, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip = True,  \n",
    "        vertical_flip=False)  \n",
    "\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    opt = Adam(lr=0.000001)\n",
    "    model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train,y_train,epochs = 500 , validation_data = (x_val, y_val))\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(500)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    predictions = model.predict_classes(x_val)\n",
    "    predictions = predictions.reshape(1,-1)[0]\n",
    "    print(classification_report(y_val, predictions, target_names = ['Not a Bicycle (Class 0)','Bicycle (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially to save images into array and pickle file\n",
    "data_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f129853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start from here\n",
    "load_saved_data()\n",
    "labels_generate()\n",
    "generate_train_val()\n",
    "data_normalize()\n",
    "main_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
